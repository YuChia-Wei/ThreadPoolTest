## CPU 密集型任務執行緒池效能測試報告

**測試目標：** 比較三種不同執行緒池設定在處理 CPU 密集型任務時的效能表現。

**測試環境：** 4 核心 CPU，4GB 記憶體

**K6 測試設定：**
*   **虛擬使用者 (VUs):** 200
*   **測試時間:** 5 分鐘
*   **每秒請求數上限 (RPS):** 50
*   **API 端點:** `/api/cpu-intensive-work?iterations=100`

---

### 測試案例分析

#### 1. Runtime-Control: .NET Runtime 動態控制執行緒
*   **測試檔案:** `k6-result-runtime-set-thread-pool-4c-4G-cpu-test.txt`

| 指標 | 結果 |
| :--- | :--- |
| **請求總數** | **1758** |
| **請求成功率** | **100%** |
| **平均響應時間 (avg)** | 38.89s |
| **P95 響應時間** | 51.41s |
| **請求速率 (reqs/s)** | 4.83/s |

**分析：**
這是表現**最好**的案例。儘管 P95 響應時間超過了 3 秒的閾值，但它成功處理了所有請求，沒有任何失敗。這顯示在 RPS (每秒請求數) 被限制的情況下，即使由 .NET Runtime 動態管理執行緒，也能夠應對壓力。然而，較長的響應時間 (平均近 40 秒) 表明，執行緒的動態生成和調度仍然帶來了顯著的延遲。

---

#### 2. Preset-ThreadPool (MinThreads: 16)
*   **測試檔案:** `k6-result-preset-thread-pool-4C-4G-cpu-test-thread-16.txt`

| 指標 | 結果 |
| :--- | :--- |
| **請求總數** | 1375 |
| **請求成功率** | 86.76% |
| **失敗率** | **13.23%** |
| **平均響應時間 (avg)** | 49.37s |
| **P95 響應時間** | 1m 6s |
| **請求速率 (reqs/s)** | 3.75/s |

**分析：**
這是表現**最差**的案例之一。將最小執行緒數設定為 16，遠低於 200 個併發使用者，導致了嚴重的瓶頸。大量的請求 (13.23%) 因為無法及時獲得執行緒而失敗。響應時間也顯著高於 Runtime-Control 的版本，顯示執行緒不足嚴重影響了系統的處理能力和穩定性。

---

#### 3. Preset-ThreadPool (MinThreads: 256)
*   **測試檔案:** `k6-result-preset-thread-pool-4C-4G-cpu-test-thread-256.txt`

| 指標 | 結果 |
| :--- | :--- |
| **請求總數** | 1170 |
| **請求成功率** | 36.23% |
| **失敗率** | **63.76%** |
| **平均響應時間 (avg)** | 58.13s |
| **P95 響應時間** | 1m 8s |
| **請求速率 (reqs/s)** | 3.19/s |

**分析：**
這是表現**最令人意外且最差**的案例。儘管預設了 256 個執行緒 (高於 200 個 VUs)，但失敗率卻是三個案例中最高的 (63.76%)。這通常暗示著**過多的執行緒造成了嚴重的上下文切換 (Context Switching) 開銷**。當大量執行緒在有限的 CPU 核心 (4 核心) 上頻繁切換時，CPU 會花費大量時間在執行緒的調度上，而不是實際執行任務，從而導致整體效能急劇下降，甚至比執行緒不足的情況更糟。

---

### 結論與建議

1.  **`rps` 限制了壓力：** 由於 K6 測試腳本中 `rps: 50` 的限制，本次測試並未完全模擬出 200 個使用者同時併發的極限壓力。即便如此，效能差異依然非常明顯。

2.  **盲目提高執行緒數是效能殺手：** 「MinThreads: 256」的案例清楚地證明，並非執行緒越多越好。過多的執行緒在 CPU 核心有限的情況下，會導致災難性的上下文切換成本，嚴重降低系統的有效處理能力。

3.  **動態控制 vs. 預設大小：**
    *   在 **RPS 受限** 的情況下，`.NET Runtime 動態控制` 的表現最佳，顯示了其在非極端併發下的彈性和效率。
    *   `預設大小 (MinThreads: 16)` 因為執行緒不足而表現不佳。
    *   `預設大小 (MinThreads: 256)` 因為執行緒過多和上下文切換而表現最差。

**後續步驟建議：**

*   **移除 `rps` 限制進行再測試：** 為了真正評估執行緒池在高併發下的極限效能，強烈建議**移除 `k6-tests/cpu-intensive-work-test.js` 中的 `rps: 50` 限制**，然後重新執行這三組測試。這將讓 200 個 VUs 對伺服器施加最大壓力，屆時「Runtime-Control」版本的效能可能會因為執行緒延遲建立而下降，而一個**合理設定**的「Preset-ThreadPool」版本（例如，接近 CPU 核心數的倍數）可能會展現出最佳效能。
